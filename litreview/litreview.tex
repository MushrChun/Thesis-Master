\chapter{Background} \label{chap:litreview}

\section{Inception of Fog Computing}
The inception of Fog Computing comes with the paper published by Bonomi et al. In that paper they discuss a relatively new computing paradigm based on the platform of internet of Things. In this paradigm, an extra layer is inserted between the cloud level and end devices level while this layer is not that close to these devices like Edge Computing units but reside a bit more far away in a more centralised way.  \cite{roman2018mobile} 

\section{Charactistics of Fog Computing}
Bonomi et al. emphasise that Fog Computing is not a substitute of Cloud Computing but an extension. They coined this concept based on the fact that the increasing demand of computing for automatically created data within IoT network. The following characteristics can be regarded as initial motivation of Fog Computing\cite{bonomi2012fog}:
\begin{itemize}
    \item Low latency and location awareness
    \item Wide-spread geographical distribution
    \item Mobility
    \item Very large number of nodes
    \item Predominant role of wireless access
    \item Strong presence of streaming and real time applications
    \item Heterogeneity
\end{itemize}

\includegraphics[width=\textwidth]{images/the_internet_of_thing_architecture_and_fog_computing.png}

\section{Scenarios of interest}

\subsection{Connected Vehicle}
Bonomi et al.\cite{bonomi2012fog}illustrate a smart traffic light system may become an suitable case applying the Fog Computing. They depict that cars are connected through local network receiving traffic support service, The connection can be via Wi-Fi, 3G, LTE, roadside units and light. In this case, there is a demand that traffic data is under real-time analysis and offer feedback correspondingly, which leading to the requirements of low latency. The high speed of vehicle intensify the significance of location awareness as well because the algorithm without overall optimisation may provide better speed performance.

\subsection{Smart Grid}
Smart grid borrows strength from Fog Computing either. The data generated by grid sensors and devices can get processed at the first tier of the Fog, called machine to machine interaction. The rest part of the layers provide analytic functionality of big data processing. 

\subsection{Wireless Sensor and Actuators Networks}
Wireless Sensors nodes are designed as an extremely low power devices, which may benefit from the shared computing capability via fog nodes. All relevant energy constrained devices are considered as advocates of the similar concept.

\subsection{Smart Building}
Beside three scenarios discussed in the paper written Bonomi et al.\cite{bonomi2012fog}, Stojmenovic et al. complement two other secnatios.\cite{stojmenovic2014fog} Smart building is one of them.

In the scenario of Smart Building, temperature, humidity and relevant environment measurements are collected and interact with each other via higher level fog node.

\subsection{Software Defined Network}
With SDN gaining more attention, studies based on it expanded to the area of Fog Computing. Stojmenovic et al. explain the Fog Computing can be used in vehicular network to apply the concept of Software Defined Network since it helps separate control and data communication layers. Furthermore, lack of communication among peers in vehicular network make Fog Computing a remedial solution when it comes to high packet loss rate.\cite{stojmenovic2014fog} 

\subsection{Augmented Reality}
Yi et al.\cite{yi2015survey} introduce more realistic scenarios in their paper and real-time video analytic is one of them. They consider the popularity of Augmented Reality products such as Google Glass and Microsoft HoloLens that demand high computation power. AR applications notoriously rely on the processing capability of hardware. Multiple sources of media are going to combined and calculated simultaneously. What's more, even a bit of latency can be sensed by users and eventually impact the outcome. On the other side, intensive computing tasks consume enormous energy, make the mobility of AR hardware unavailable. 

Fog Computing can be plugged to this case. Since we do not push the computing nodes far away from the data, the latency can be ensured. Meanwhile, it saves the power of the devices because these power-consuming tasks are diverted to external hardware and only basic network I/O is contained.

\subsection{Content Delivery and Caching}
Zhu et al. contribute to another scenario of Fog Computing. In their paper, Fog Computing nodes are used as Content Delivery Network nodes. They believe that most of time wasted in the front-end rendering and execution can be saved if cache is optimised and static resources are better compressed. Their concept of Fog Computing is higher level of Edge Computing. In other words, Fog Computing nodes are more centralised and offer the bridge between cloud and end users. In the scenario, the end users are equipped with computing power to some degree and are not as power sensitive as nodes in wireless network. As a result, higher level of Fog Computing nodes play the role of distributed tasks of Cloud Computing. They help preprocess web objects, page components and minimise traffic.

\subsection{Mobile Big Data Analytic}
The same authors also mention the significance of Fog Computing in the scenario of big data processing. Consider the high demand of Cloud Computing as the resource of big data analysis, relevant tasks pop up dramatically. Sometimes, the Cloud Computing node are far away from end users and low latency top the requirement, Fog Computing nodes become decent alternative. In this use case, Fog Computing strengthen their feature of elasticity and scalability just like the Could counterpart.